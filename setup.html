<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Player Re-Identification Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f9f9f9;
            color: #333;
            margin: 0;
            padding: 2rem;
        }
        header {
            background-color: #0052cc;
            color: white;
            padding: 1.5rem;
            text-align: center;
            border-radius: 8px;
        }
        section {
            background-color: white;
            padding: 1.5rem;
            margin: 2rem 0;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        h2 {
            color: #0052cc;
        }
        code {
            background-color: #eef;
            padding: 2px 4px;
            border-radius: 4px;
        }
        pre {
            background-color: #eef;
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <header>
        <h1>Player Re-Identification Using YOLOv11</h1>
        <p>Video-Based Player Detection and Tracking Project Report</p>
    </header>

    <section>
        <h2>âœ¨ Overview</h2>
        <p>
            This project aims to identify and consistently track players from a single video feed using the YOLOv11 object detection model.
            It assigns persistent IDs to players across frames based on appearance features.
        </p>
    </section>

    <section>
        <h2>âœ… What I Did</h2>
        <ul>
            <li>Loaded and used a custom-trained YOLOv11 model for player detection.</li>
            <li>Implemented a feature-based Re-ID tracker using cosine similarity.</li>
            <li>Visualized player IDs and bounding boxes on each frame.</li>
            <li>Saved the annotated video output to <code>output/reid_result.mp4</code>.</li>
        </ul>
    </section>

    <section>
        <h2>ğŸ“‚ Project Structure</h2>
        <pre><code>project-folder/
â”œâ”€â”€ input/
â”‚   â””â”€â”€ 15sec_input_720p.mp4
â”œâ”€â”€ output/
â”‚   â””â”€â”€ reid_result.mp4
â”œâ”€â”€ yolov11/
â”‚   â””â”€â”€ yolov11_custom.pt
â”œâ”€â”€ detector.py
â”œâ”€â”€ tracker.py
â”œâ”€â”€ main.py
â”œâ”€â”€ utils.py
â””â”€â”€ requirements.txt</code></pre>
    </section>

    <section>
        <h2>âš™ï¸ Setup & Run Instructions</h2>
        <p>Follow these steps to run the project locally:</p>
        <h4>1. Create Virtual Environment and Install Dependencies</h4>
        <pre><code>python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt</code></pre>

        <h4>2. Run the Script</h4>
        <pre><code>python main.py</code></pre>

        <p>The output will be saved at: <code>output/reid_result.mp4</code></p>
    </section>

    <section>
        <h2>ğŸ“Š Results</h2>
        <p>The system successfully assigns and maintains unique player IDs throughout the 15-second video, visible in <code>output/reid_result.mp4</code>.</p>
        <p>Tracking is based on basic appearance features and performs well under short-term occlusions.</p>
    </section>

    <section>
        <h2>ğŸ” Future Enhancements</h2>
        <ul>
            <li>Use a CNN-based feature extractor (e.g., ResNet or MobileNet).</li>
            <li>Incorporate motion-based tracking (e.g., DeepSORT or ByteTrack).</li>
            <li>Extend to multi-camera Re-ID and long-term tracking.</li>
        </ul>
    </section>

    <section>
        <h2>ğŸ‰ Final Output</h2>
        <p>âœ… <strong>Output Video:</strong> <code>output/reid_result.mp4</code></p>
    </section>
</body>
</html>